{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "As the assignment specifies that we must use vanilla python, I implemented the feature without numpy, I also created a printConvolved function so that it would be easier to read the output. I also assumed that the stride would always be 1, so as to simplify the question since it was never specified.\n",
    "\n",
    "To convolve a matrix, I simply loop through all the points that could be multiplied by the top left corner element in the kernel, I then get the local matrix, a sub matrix that contains the points that will be multiplied by the kernel for this iteration, and since this is done in vanilla python I have to multiply the matrix out, the flatten it to a 1d list, then sum the values inside to get an element in the convolved array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(n, k):\n",
    "    outputLen = len(n) - len(k) + 1\n",
    "\n",
    "    convMatrix = []\n",
    "    localMatrixSizeModifier = len(k)\n",
    "    for row in range(outputLen):\n",
    "        convRow = []\n",
    "        for col in range(outputLen):\n",
    "            localMatrix = [i[col : col + localMatrixSizeModifier] for i in n[row : row + localMatrixSizeModifier]]\n",
    "            multMatrices = [[x * y for x, y in zip(a, b)] for a, b in zip(localMatrix, k)]\n",
    "            flattenedMatrices = sum(multMatrices, [])\n",
    "            convRow.append(sum(flattenedMatrices))\n",
    "        convMatrix.append(convRow)\n",
    "    return convMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The print function will simply add walls to the ends of each row, and will add the correct number of spaces for each each input so that they will all sit at a uniform starting place for the first number, the largest number is considered to be in the thousands, and a space before any number if it is not negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def printConvolved(c):\n",
    "    for row in c:\n",
    "        toPrint = '|'\n",
    "        for elem in row:\n",
    "            if elem != 0:\n",
    "                newElem = ''\n",
    "                logged = math.log10(abs(elem))\n",
    "                if logged % 1 != 0:\n",
    "                    spaces = 5 - (math.ceil(logged))\n",
    "                else:\n",
    "                    spaces = 4 - (math.ceil(logged))\n",
    "                newElem = str(elem) + (' ' * spaces)\n",
    "                if elem > 0:\n",
    "                    newElem = ' ' + newElem\n",
    "                toPrint += newElem\n",
    "            else:\n",
    "                toPrint += ' ' + str(elem) + (' ' * 4)\n",
    "        print(toPrint + '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-1    -4    -14   |\n",
      "| 6    -3    -13   |\n",
      "| 9    -6    -8    |\n"
     ]
    }
   ],
   "source": [
    "n = [[1, 2, 3, 4, 5], \n",
    "    [1, 3, 2, 3, 10], \n",
    "    [3, 2, 1, 4, 5], \n",
    "    [6, 1, 1, 2, 2], \n",
    "    [3, 2, 1, 5, 4]]\n",
    "k = [[1, 0, -1], \n",
    "    [1, 0, -1], \n",
    "    [1, 0, -1]]\n",
    "\n",
    "printConvolved(convolve(n, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "The image I used for this was a black square that was placed on a 40x40 white page, the square does not take up the whole page, I chose this size because on my 13\" screen, when convolved and printed with the function I made, it fits perfectly width wise in a terminal, making it easy to read and understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     28    97    165   204   200   197   205   203   205   197   201   201   201   201   201   201   197   205   203   205   197   200   204   165   97    28    0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     100   163   117   344   358   373   378   286   396   359   363   363   363   363   363   363   359   396   286   378   373   358   344   117   163   100   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     160   82   -908  -577  -536  -573  -567  -506  -567  -568  -564  -564  -564  -564  -564  -564  -568  -567  -506  -567  -573  -536  -577  -908   82    160   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     205   421  -577  -4    -11   -17   -19   -15   -10   -3     0     0     0     0     0     0    -3    -10   -15   -19   -17   -11   -4    -577   421   205   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     194   302  -579   45   -16    50    32   -9     23   -3     0     0     0     0     0     0    -3     23   -9     32    50   -16    45   -579   302   194   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     203   419  -568  -15   -22   -21   -19   -6    -10   -3     0     0     0     0     0     0    -3    -10   -6    -19   -21   -22   -15   -568   419   203   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     195   333  -576  -15    71   -13   -14    41   -11   -2    -3    -3    -3    -3    -3    -3    -2    -11    41   -14   -13    71   -15   -576   333   195   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     202   376  -519  -21   -18   -8     12    14   -11    6     6     6     6     6     6     6     6    -11    14    12   -8    -18   -21   -519   376   202   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     200   346  -576   23    9     10   -9    -8     3    -4    -3    -3    -3    -3    -3    -3    -4     3    -8    -9     10    9     23   -576   346   200   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     202   362  -560  -8    -8    -4    -2    -3     6    -3     0     0     0     0     0     0    -3     6    -3    -2    -4    -8    -8    -560   362   202   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     201   360  -558  -3     0     0     0    -3     6    -3     0     0     0     0     0     0    -3     6    -3     0     0     0    -3    -558   360   201   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     202   362  -560  -8    -8    -4    -2    -3     6    -3     0     0     0     0     0     0    -3     6    -3    -2    -4    -8    -8    -560   362   202   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     200   346  -576   23    9     10   -9    -8     3    -4    -3    -3    -3    -3    -3    -3    -4     3    -8    -9     10    9     23   -576   346   200   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     202   376  -519  -21   -18   -8     12    14   -11    6     6     6     6     6     6     6     6    -11    14    12   -8    -18   -21   -519   376   202   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     195   333  -576  -15    71   -13   -14    41   -11   -2    -3    -3    -3    -3    -3    -3    -2    -11    41   -14   -13    71   -15   -576   333   195   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     203   419  -568  -15   -22   -21   -19   -6    -10   -3     0     0     0     0     0     0    -3    -10   -6    -19   -21   -22   -15   -568   419   203   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     194   302  -579   45   -16    50    32   -9     23   -3     0     0     0     0     0     0    -3     23   -9     32    50   -16    45   -579   302   194   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     205   421  -577  -4    -11   -17   -19   -15   -10   -3     0     0     0     0     0     0    -3    -10   -15   -19   -17   -11   -4    -577   421   205   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     160   82   -908  -577  -536  -573  -567  -506  -567  -568  -564  -564  -564  -564  -564  -564  -568  -567  -506  -567  -573  -536  -577  -908   82    160   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     100   163   117   344   358   373   378   286   396   359   363   363   363   363   363   363   359   396   286   378   373   358   344   117   163   100   0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     28    97    165   204   200   197   205   203   205   197   201   201   201   201   201   201   197   205   203   205   197   200   204   165   97    28    0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "| 0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0     0    |\n",
      "\n",
      "\n",
      "\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1048  1089  1088  1087  1085  1085  1095  1083  1087  1087  1087  1087  1087  1087  1087  1087  1083  1095  1085  1085  1087  1088  1089  1048  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1048  937   810   867   868   887   895   796   913   869   873   873   873   873   873   873   869   913   796   895   887   868   867   810   937   1048  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1092  778  -297  -202  -157  -194  -197  -124  -199  -188  -188  -188  -188  -188  -188  -188  -188  -199  -124  -197  -194  -157  -202  -297   778   1092  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1080  940  -206   9     2    -8    -5    -7    -3     0     0     0     0     0     0     0     0    -3    -7    -5    -8     2     9    -206   940   1080  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1093  812  -188   46   -14    51    33   -9     24   -3     0     0     0     0     0     0    -3     24   -9     33    51   -14    46   -188   812   1093  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1081  929  -194  -6    -9    -7    -6     2    -4     0     0     0     0     0     0     0     0    -4     2    -6    -7    -9    -6    -194   929   1081  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1089  849  -192  -9     72   -10   -9     44   -6    -1    -1    -1    -1    -1    -1    -1    -1    -6     44   -9    -10    72   -9    -192   849   1089  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1085  886  -142  -10   -12    3     20    15   -5     7     6     6     6     6     6     6     7    -5     15    20    3    -12   -10   -142   886   1085  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1088  863  -198   30    10    13   -5    -4     7    -2    -1    -1    -1    -1    -1    -1    -2     7    -4    -5     13    10    30   -198   863   1088  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  873  -181  -5    -2    -2     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0    -2    -2    -5    -181   873   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  872  -182  -1     0     0     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0     0     0    -1    -182   872   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1087  873  -181  -5    -2    -2     0    -1     6    -1     0     0     0     0     0     0    -1     6    -1     0    -2    -2    -5    -181   873   1087  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1088  863  -198   30    10    13   -5    -4     7    -2    -1    -1    -1    -1    -1    -1    -2     7    -4    -5     13    10    30   -198   863   1088  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1085  886  -142  -10   -12    3     20    15   -5     7     6     6     6     6     6     6     7    -5     15    20    3    -12   -10   -142   886   1085  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1089  849  -192  -9     72   -10   -9     44   -6    -1    -1    -1    -1    -1    -1    -1    -1    -6     44   -9    -10    72   -9    -192   849   1089  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1081  929  -194  -6    -9    -7    -6     2    -4     0     0     0     0     0     0     0     0    -4     2    -6    -7    -9    -6    -194   929   1081  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1093  812  -188   46   -14    51    33   -9     24   -3     0     0     0     0     0     0    -3     24   -9     33    51   -14    46   -188   812   1093  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1080  940  -206   9     2    -8    -5    -7    -3     0     0     0     0     0     0     0     0    -3    -7    -5    -8     2     9    -206   940   1080  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1092  778  -297  -202  -157  -194  -197  -124  -199  -188  -188  -188  -188  -188  -188  -188  -188  -199  -124  -197  -194  -157  -202  -297   778   1092  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1048  937   810   867   868   887   895   796   913   869   873   873   873   873   873   873   869   913   796   895   887   868   867   810   937   1048  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1048  1089  1088  1087  1085  1085  1095  1083  1087  1087  1087  1087  1087  1087  1087  1087  1083  1095  1085  1085  1087  1088  1089  1048  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n",
      "| 1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020  1020 |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "\n",
    "im = Image.open('square.jpg')\n",
    "rgb = np.array(im.convert('RGB'))\n",
    "r = rgb[:,:,0]\n",
    "\n",
    "kernel1 = [[-1, -1, -1], \n",
    "           [-1, 8, -1], \n",
    "           [-1, -1, -1]]\n",
    "kernel2 = [[0, -1, 0], \n",
    "           [-1, 8, -1], \n",
    "           [0, -1, 0]]\n",
    "con1 = convolve(r, kernel1)\n",
    "printConvolved(con1)\n",
    "print(\"\\n\\n\")\n",
    "con2 = convolve(r, kernel2)\n",
    "printConvolved(con2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)\n",
    "The code here creates a convolutional neural network where each hidden layer uses relu for the activation function, 3x3 kernels and same padding. The first layer makes 16 output channels, the second layer has 16 output channels and uses a stride of 2, the third layer outputs 32 channels, and the 4th hidden layer outputs 32 channels and uses a stride of 2 again. We use a dropout regularizer of 50% and then use a soft max dense layer with an l1 regularizer with c = 0.0001.\n",
    "\n",
    "It uses batch sizes of 128 and will train the model over 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, LeakyReLU, MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "n=5000\n",
    "\n",
    "# takes the first 5000 datapoints in x_train and y_train\n",
    "x_train = x_train[1:n]; y_train=y_train[1:n]\n",
    "#x_test=x_test[1:500]; y_test=y_test[1:500]\n",
    "\n",
    "# images are originaly in 0-255 values, regularize them to 0-1\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "print(\"orig x_train shape:\", x_train.shape)\n",
    "\n",
    "# data currently saved as a vector with numbers 0-9, instead, turn each y into a list of binary numbers, with 9 elements in each list\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "use_saved_model = False\n",
    "if use_saved_model:\n",
    "    model = keras.models.load_model(\"cifar.model\")\n",
    "else:\n",
    "    model = keras.Sequential()\n",
    "    model.add(Conv2D(16, (3,3), padding='same', input_shape=x_train.shape[1:],activation='relu'))\n",
    "    model.add(Conv2D(16, (3,3), strides=(2,2), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(32, (3,3), strides=(2,2), padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax',kernel_regularizer=regularizers.l1(0.0001)))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 20\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    model.save(\"cifar.model\")\n",
    "    plt.subplot(211)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.subplot(212)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss'); plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "preds = model.predict(x_train)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_train1 = np.argmax(y_train, axis=1)\n",
    "print(classification_report(y_train1, y_pred))\n",
    "print(confusion_matrix(y_train1,y_pred))\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_test1 = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_test1, y_pred))\n",
    "print(confusion_matrix(y_test1,y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
